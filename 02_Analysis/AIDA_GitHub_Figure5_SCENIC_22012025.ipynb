{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [\"Chinese\", \"Malay\", \"Indian\"]:\n",
    "    for i in range(1,11,1):\n",
    "        Regulons = \"/rfs-storageservice/GIS/Projects/LOSBDA/Radhika/Final_Analysis/PB/30GRNBoost/\" + k[0] + \"R/T\" + str(i) + \"/reg_PB.csv\"\n",
    "        Output = \"/rfs-storageservice/GIS/Projects/LOSBDA/Radhika/Final_Analysis/PB/30GRNBoost/\" + k[0] + \"R/T\" + str(i) + \"/AUCell_Output.loom\"\n",
    "        !pyscenic aucell \\\n",
    "       \"/scratch/users/astar/gis/sonthaliar/Pyscenic/PB_All_SG_libs/PB_ExpMatrix_Sum_All.loom\" \\\n",
    "        {Regulons} \\\n",
    "        --output {Output} \\\n",
    "        --num_workers 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loompy as lp \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ranksums\n",
    "\n",
    "##The working directory needs the PB (summed count activity matrix) in the format  DCP_ID__Annotations_lvl2__Sex__Ethnicity with its index\n",
    "\n",
    "def Pipeline_WRS_ForMultipleEth_PB(auc_mtx, Trial_Number): \n",
    "    \n",
    "    def p_adjust_bh(p):\n",
    "        p = np.asfarray(p)\n",
    "        by_descend = p.argsort()[::-1] #returns the index \n",
    "        by_orig = by_descend.argsort()\n",
    "        steps = float(len(p)) / np.arange(len(p), 0, -1)\n",
    "        q = np.minimum(1, np.minimum.accumulate(steps * p[by_descend]))\n",
    "        return q[by_orig]\n",
    "\n",
    "    def Wilcoxon_Rank_Sum (list_of_Regulons, Ethnicity): \n",
    "            AM = auc_mtx\n",
    "            if Ethnicity != \"All\":\n",
    "                S1 = AM[(AM[\"Sex\"] == \"Male\") & (AM[\"Ethnicity\"] == Ethnicity)]\n",
    "                S2 = AM[(AM[\"Sex\"] == \"Female\") & (AM[\"Ethnicity\"] == Ethnicity)]\n",
    "            else:\n",
    "                S1 = AM[(AM[\"Sex\"] == \"Male\")]\n",
    "                S2 = AM[(AM[\"Sex\"] == \"Female\")]\n",
    "                \n",
    "            finalContainerDictionary = {}    \n",
    "            for i in list(set(S1[\"Annotations_lvl2\"].unique()) & set(S2[\"Annotations_lvl2\"].unique())): \n",
    "                replacements = {'+': 'positive', '-': 'negative'}\n",
    "                replaced_chars = [replacements.get(char, char) for char in i] #removing + & - \n",
    "                new = ''.join(replaced_chars)\n",
    "                locals()[ new + 'Dict_With_WRS'] = {} \n",
    "                for j in list_of_Regulons:\n",
    "                    locals()[new + 'Dict_With_WRS'][j] = ranksums(S1[S1[\"Annotations_lvl2\"] == i][j], S2[S2[\"Annotations_lvl2\"] == i][j], alternative='two-sided')\n",
    "                    Appending_letter = \"TestPB\"\n",
    "                    tempDataframe = pd.DataFrame(locals()[new + 'Dict_With_WRS'])\n",
    "                    tempDataframe = tempDataframe.T\n",
    "                    tempDataframe.columns = [\"Test_Statistic\", \"p value\"]\n",
    "                    tempDataframe[\"FDR Non-Global\"] = p_adjust_bh(list(tempDataframe[\"p value\"]))\n",
    "                    finalContainerDictionary[new + Appending_letter + Ethnicity[0]] = tempDataframe\n",
    "            \n",
    "            return finalContainerDictionary\n",
    "\n",
    "    List_With_MetaData_Info = [[\"Annotations_lvl2\", 1], [\"Sex\", 2], [\"DCP_ID\", 0], [\"Ethnicity\", 3]]\n",
    "    \n",
    "    def Function_Metadata_Addition(subset):\n",
    "        for i in range(len(List_With_MetaData_Info)):\n",
    "            locals()[List_With_MetaData_Info[i][0]] = list()\n",
    "            for k in subset.index:\n",
    "                locals()[List_With_MetaData_Info[i][0]].append(k.split(\"__\")[List_With_MetaData_Info[i][1]])\n",
    "            subset[List_With_MetaData_Info[i][0]] = locals()[List_With_MetaData_Info[i][0]] \n",
    "    \n",
    "    Function_Metadata_Addition(auc_mtx)    \n",
    "\n",
    "    auc_mtx = auc_mtx[~auc_mtx[\"Annotations_lvl2\"].isin([\"pDC\", \"mDC\", \"Plasma B\", \"flagged_cluster\"])] #only retaining main cell types\n",
    "    Regulons = auc_mtx.filter(like='+', axis=1).columns\n",
    "\n",
    "\n",
    "    #Running the pipeline for PB \n",
    "    PB_global = {}\n",
    "    for Eth in [\"Chinese\", \"Malay\", \"Indian\", \"All\"]:\n",
    "        if Eth != \"All\":\n",
    "            Subset_Male = auc_mtx[(auc_mtx[\"Sex\"] == \"Male\") & (auc_mtx[\"Ethnicity\"] == Eth)]\n",
    "            Subset_Female = auc_mtx[(auc_mtx[\"Sex\"] == \"Female\") & (auc_mtx[\"Ethnicity\"] == Eth)]\n",
    "        else:\n",
    "            Subset_Male = auc_mtx[auc_mtx[\"Sex\"] == \"Male\"]\n",
    "            Subset_Female = auc_mtx[auc_mtx[\"Sex\"] == \"Female\"]\n",
    "        \n",
    "        DataframesPB = Wilcoxon_Rank_Sum(Regulons, Eth)\n",
    "        \n",
    "        list_Annotations_PB = list()\n",
    "        list_of_p_values_PB = list()\n",
    "        for i in list(set(Subset_Male[\"Annotations_lvl2\"].unique()) & set(Subset_Female[\"Annotations_lvl2\"].unique())):\n",
    "                replacements = {'+': 'positive', '-': 'negative'}\n",
    "                replaced_chars = [replacements.get(char, char) for char in i] #removing + & - \n",
    "                new = ''.join(replaced_chars)\n",
    "                list_Annotations_PB.append(new + \"TestPB\" + Eth[0])\n",
    "                list_of_p_values_PB.append((DataframesPB[new + \"TestPB\" + Eth[0]][\"p value\"]))\n",
    "        flat_list = [item for sublist in list_of_p_values_PB for item in sublist] ##Using the p values from flat list > we know index 24 = ILC\n",
    "        Adjusted_p_PB = p_adjust_bh(flat_list)\n",
    "        for CellType in list_Annotations_PB:\n",
    "            DataframesPB[CellType][\"FDR Global\"] = np.array_split(Adjusted_p_PB, len(set(Subset_Male[\"Annotations_lvl2\"].unique()) & set(Subset_Female[\"Annotations_lvl2\"].unique())))[list_Annotations_PB.index(CellType)] ##split into 25 parts, index = 24 ILC\n",
    "        PB_global.update(DataframesPB)\n",
    "    \n",
    "    return PB_global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scanpy as sc\n",
    "import matplotlib as mpl\n",
    "from matplotlib import ticker as mtick\n",
    "from matplotlib import ticker\n",
    "# plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "def AUC_Histogram_PB(auc_mtx, Regulons, Cell_Type, Ethnicity, nbins, Trial_Number, Regulons_from, Regulon_Label_Size, pvalSize):\n",
    "    sns.set_theme( rc={\n",
    "    'xtick.bottom': True,\n",
    "    'ytick.left': True,})\n",
    "    \n",
    "#     csfont = {'fontname':'Arial'}\n",
    "    def fmt_SF_Digits(x, pos):\n",
    "        return f'{x:.4f}'\n",
    "    Dict = PB\n",
    "    palette_updated ={\"Male\": \"blue\", \"Female\": \"#C51B8A\"}\n",
    "    replacements = {'+': 'positive', '-': 'negative'}\n",
    "    replaced_chars = [replacements.get(char, char) for char in Cell_Type] #removing + & -\n",
    "    new = ''.join(replaced_chars)\n",
    "    new_updated = new + \"TestPB\"\n",
    "    Regulons = Regulons\n",
    "    temp =  math.ceil(len(Regulons)/2) #gives you the number of rows!\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=(2*int(temp)), ncols=2, figsize=(17, (temp*12.5)), gridspec_kw={\"height_ratios\": (int(temp))*[1,3]}) #2x3 , you want 1 row & 3 columns\n",
    "    #gs = fig.add_gridspec(nrows=2*int(temp), ncols= 4,  gridspec_kw={\"height_ratios\": 2*int(temp)*[1,3]})\n",
    "    fig.suptitle(Cell_Type + \"_\" + \"PB input\" + \"_\" + Trial_Number + \"_\" + Regulons_from + \"_\" + Ethnicity , fontsize = 30, y = 0.95)\n",
    "#    fig.suptitle(\"Sample \" + \"Regulon Label = \" + str(Regulon_Label_Size) + \",p value label signs = \" + str(pvalSize) , fontsize = 30, y = 0.95)\n",
    "    df = auc_mtx[(auc_mtx[\"Annotations_lvl2\"] == Cell_Type) & (auc_mtx[\"Ethnicity\"] == Ethnicity)]\n",
    "    \n",
    "    count_1 = -1\n",
    "    count_2 = -1\n",
    "    for i in range(0,(2*int(temp)),1):\n",
    "        for j in range(0,4,1):\n",
    "            if (i % 2) == 0 :\n",
    "                count_1 += 1\n",
    "                if count_1 < (len(Regulons)):\n",
    "                    min_val = df[Regulons[count_1]].min()\n",
    "                    max_val = df[Regulons[count_1]].max()\n",
    "                    val_width = max_val - min_val\n",
    "                    n_bins = 10\n",
    "                    bin_width = val_width/n_bins\n",
    "        \n",
    "                    plot_box = sns.boxplot(ax = axes[i,j], x = df[Regulons[count_1]], y = df[\"Sex\"], hue = df[\"Sex\"], palette = palette_updated, boxprops=dict(alpha=.3), order=[\"Male\", \"Female\"], flierprops={'marker': 'o'}, hue_order=[\"Male\", \"Female\"])\n",
    "                    plot_box.get_legend().remove()\n",
    "                    axes[i,j].tick_params(axis = \"x\", labelrotation = 45, bottom = \"on\", labelsize = \"large\")\n",
    "                    axes[i,j].tick_params(axis = \"y\",  labelsize = \"large\")\n",
    "                    plot_box.set_ylabel(\"Sex\", fontsize=20)\n",
    "                    #plot_box.set(xlabel=None)\n",
    "                    plot_box.set_xlabel(Regulons[count_1],fontsize=Regulon_Label_Size)\n",
    "                    plt.setp(axes[i,j], xticks=np.arange(min_val-bin_width/2, max_val+bin_width/2, bin_width), visible = True)\n",
    "                    axes[i,j].xaxis.set_major_formatter(ticker.FuncFormatter(fmt_SF_Digits))\n",
    "\n",
    "            else:\n",
    "                count_2 += 1\n",
    "                if count_2 < (len(Regulons)):\n",
    "                    min_val = df[Regulons[count_2]].min()\n",
    "                    max_val = df[Regulons[count_2]].max()\n",
    "                    n_bins = 10\n",
    "                    val_width = max_val - min_val\n",
    "                    bin_width = val_width/n_bins\n",
    "                    plot_a = sns.histplot(ax = axes[i,j],data =  df, x = Regulons[count_2], hue='Sex', stat = 'percent', common_norm = False, palette= palette_updated, bins = nbins, legend = False, hue_order = [\"Male\", \"Female\"], multiple = \"dodge\", shrink=0.6)\n",
    "#                     plot_a.suptitle(\"Trial\",  fontsize = 30, y = 0.92)\n",
    "                    plot_a.set_xlabel(Regulons[count_2] ,fontsize=Regulon_Label_Size)\n",
    "                    plot_a.set_ylabel(\"Percent\" ,fontsize=20)\n",
    "                    pval = \"p-value = \" + str(\"{:.2e}\".format(Dict[new_updated + Ethnicity[0]].T[Regulons[count_2]][\"p value\"]))\n",
    "                    FDRGlobal = \"FDR = \" + str(\"{:.2e}\".format(Dict[new_updated + Ethnicity[0]].T[Regulons[count_2]][\"FDR Global\"]))\n",
    "                    FDR_NonGlobal = \"Regulon-specific FDR = \" + str(\"{:.2e}\".format(Dict[new_updated + Ethnicity[0]].T[Regulons[count_2]][\"FDR Non-Global\"]))\n",
    "                    string_with_info = '\\n'.join([str(pval), str(FDRGlobal), str(FDR_NonGlobal)])\n",
    "#                     plt.text(1,1, string_with_info, ha = 'right', va = 'top', transform=axes[i,j].transAxes, fontsize = 15 )\n",
    "                    plot_a.tick_params(axis = \"x\", labelsize = \"large\", labelrotation = 45) #direction = \"out\", length = 10, width = 10, colors = \"r\")\n",
    "                    plt.subplots_adjust(wspace=0.2,hspace= 0.6)\n",
    "#                     axes[i,j].title(label = \"Trial\")\n",
    "                    plot_a.set_title(string_with_info, loc = \"right\", fontsize = pvalSize)\n",
    "                    plot_a.tick_params(axis = \"y\",  labelsize = \"large\")\n",
    "                    plt.setp(axes[i,j], xticks=np.arange(min_val-bin_width/2, max_val+bin_width/2, bin_width), visible = True)\n",
    "                    axes[i,j].xaxis.set_major_formatter(ticker.FuncFormatter(fmt_SF_Digits))\n",
    "\n",
    "\n",
    "\n",
    "            fig.savefig(\"/rfs-storageservice/GIS/Projects/LOSBDA/Radhika/Final_Analysis/PB/30GRNBoost/\" + Regulons_from + \"/Plots/\"  + Cell_Type + \"_\" + Trial_Number + \"_\" + Ethnicity + \".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for Regulons in [\"CR\", \"MR\", \"IR\"]:\n",
    "    for trial in range(1,11,1):\n",
    "        lf = lp.connect( \"/rfs-storageservice/GIS/Projects/LOSBDA/Radhika/Final_Analysis/PB/30GRNBoost/\" + Regulons + \"/T\" + str(trial) + \"/AUCell_Output.loom\", mode='r', validate=False )\n",
    "        auc_mtx = pd.DataFrame(lf.ca.RegulonsAUC, index=lf.ca.CellID)\n",
    "        lf.close()\n",
    "        Rownames = pd.read_csv(\"/scratch/users/astar/gis/sonthaliar/Pyscenic/Regulons_Diff_Trial_Chinese/Rownames.csv\")\n",
    "        auc_mtx.index = Rownames[\"Pseudobulk\"]\n",
    "        PB = Pipeline_WRS_ForMultipleEth_PB(auc_mtx, str(trial))\n",
    "        for Eth in [\"Chinese\", \"Malay\", \"Indian\"]:\n",
    "            AUC_Histogram_PB(auc_mtx, [\"ZBTB7A(+)\", \"SP1(+)\"], \"Treg\", Eth, 10, str(trial), Regulons, 25, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.AUC_Histogram_Trial_PB(auc_mtx, Regulons, Cell_Type, Ethnicity, nbins, Trial_Number, Regulons_from, Regulon_Label_Size, pvalSize)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
